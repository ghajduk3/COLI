{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDMqDAAAmiLD"
      },
      "source": [
        "**I/O device register**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2q6Ix5Fl2s3",
        "outputId": "e6191242-6647-4a66-9184-ee04ceabe8a6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek7kHsU3nTBN"
      },
      "source": [
        "**Install required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yKQ4IG6nXJT",
        "outputId": "7716d0d3-9a76-495f-e997-9aceaa58d1fe"
      },
      "source": [
        "!pip3 install transformers pandas nltk spacy classla"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting classla\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/be/d631a7bb19101c87d608426e50624add2370cc7fe19c6775a9ad4d39f280/classla-1.0.1-py3-none-any.whl (259kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 14.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from classla) (3.12.4)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from classla) (1.8.0+cu111)\n",
            "Collecting obeliks\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/80/938665c333d3f4903e2ddde4b55f1fba8b659d2e175732bfb4c76415d757/obeliks-1.0.4.tar.gz\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from obeliks->classla) (4.2.6)\n",
            "Building wheels for collected packages: obeliks\n",
            "  Building wheel for obeliks (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for obeliks: filename=obeliks-1.0.4-cp37-none-any.whl size=14931 sha256=e5441acbc372cd5f0360bb22795b42e3e57ada75efb865d499154c76cef08239\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/42/8a/37d003a1d0613c2388b02bebc4b40c577320a1397e0ae9a7bc\n",
            "Successfully built obeliks\n",
            "Installing collected packages: obeliks, classla\n",
            "Successfully installed classla-1.0.1 obeliks-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN64HZQ1nqfG",
        "outputId": "c84e7147-d30c-4db3-8553-1f79aaa36153"
      },
      "source": [
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html \n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.8.0+cu111 in /usr/local/lib/python3.7/dist-packages (1.8.0+cu111)\n",
            "Requirement already satisfied: torchvision==0.9.0+cu111 in /usr/local/lib/python3.7/dist-packages (0.9.0+cu111)\n",
            "Requirement already satisfied: torchaudio==0.8.0 in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1d1mY1A_i-3"
      },
      "source": [
        "# Random seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsKRLWda4Vzr"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "seed_val = 2021\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gi3WN8PCvwO"
      },
      "source": [
        "# BERT "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ncO0nQDosXU"
      },
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gZZzKq7owzA"
      },
      "source": [
        "def setup_classifier(\n",
        "    model_name: str,\n",
        "    num_labels: int) -> BertForSequenceClassification:\n",
        "\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels = num_labels,\n",
        "        output_attentions = False,\n",
        "        output_hidden_states = False,\n",
        "    )\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g4etr1so1f3"
      },
      "source": [
        "def setup_data(\n",
        "    model_name: str,\n",
        "    x: pd.DataFrame, \n",
        "    y: pd.DataFrame,\n",
        "    do_lower_case: bool,\n",
        "    max_length: int) -> TensorDataset:\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case = do_lower_case)\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in x:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens = True,\n",
        "            max_length = max_length,\n",
        "            padding='max_length',\n",
        "            return_attention_mask = True,\n",
        "            return_tensors = 'pt',\n",
        "            truncation = True\n",
        "        )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    \n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(y)\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "    return dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw9DF4H3o5NS"
      },
      "source": [
        "def train_classifier(\n",
        "    model: BertForSequenceClassification, \n",
        "    dataset: TensorDataset, \n",
        "    validation_ratio: float,\n",
        "    batch_size: int,\n",
        "    freeze_embeddings_layer: bool,\n",
        "    freeze_encoder_layers: int,\n",
        "    epochs: int) -> (BertForSequenceClassification, list):\n",
        "\n",
        "    device = select_device()\n",
        "\n",
        "    train_size = int(validation_ratio * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        sampler = RandomSampler(train_dataset),\n",
        "        batch_size = batch_size\n",
        "    )\n",
        "\n",
        "    validation_dataloader = DataLoader(\n",
        "        val_dataset,\n",
        "        sampler = SequentialSampler(val_dataset),\n",
        "        batch_size = batch_size\n",
        "    )\n",
        "\n",
        "    modules = []\n",
        "\n",
        "    if freeze_embeddings_layer:\n",
        "        modules.append(model.bert.embeddings)\n",
        "    \n",
        "    for i in range(freeze_encoder_layers):\n",
        "        modules.append(model.bert.encoder.layer[i])\n",
        "\n",
        "    for module in modules:\n",
        "        for param in module.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = AdamW(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr = 2e-5,\n",
        "        eps = 1e-8\n",
        "    )\n",
        "\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps = 0,\n",
        "        num_training_steps = total_steps\n",
        "    )\n",
        "\n",
        "    training_stats = []\n",
        "\n",
        "    total_t0 = time.time()\n",
        "\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        total_train_loss = 0\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            model.zero_grad()        \n",
        "\n",
        "            outputs = model(\n",
        "                b_input_ids, \n",
        "                token_type_ids = None, \n",
        "                attention_mask = b_input_mask, \n",
        "                labels = b_labels\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "        \n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "\n",
        "        for batch in validation_dataloader:\n",
        "            \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "\n",
        "                outputs = model(\n",
        "                    b_input_ids, \n",
        "                    token_type_ids = None, \n",
        "                    attention_mask = b_input_mask,\n",
        "                    labels = b_labels\n",
        "                )\n",
        "                \n",
        "                loss = outputs.loss\n",
        "                logits = outputs.logits\n",
        "                \n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "            \n",
        "\n",
        "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "        \n",
        "        validation_time = format_time(time.time() - t0)\n",
        "        \n",
        "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "    return model, training_stats"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_1G3NNIo-P0"
      },
      "source": [
        "def test_classifier(\n",
        "    model: BertForSequenceClassification, \n",
        "    dataset: TensorDataset,\n",
        "    batch_size: int):\n",
        "\n",
        "    device = select_device()\n",
        "\n",
        "    prediction_dataloader = DataLoader(\n",
        "        dataset, \n",
        "        sampler = SequentialSampler(dataset), \n",
        "        batch_size = batch_size\n",
        "    )\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Prediction...\")\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    predictions , true_labels = [], []\n",
        "\n",
        "    for batch in prediction_dataloader:\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2]\n",
        "        \n",
        "        with torch.no_grad():\n",
        "\n",
        "            outputs = model(\n",
        "                b_input_ids, \n",
        "                token_type_ids = None, \n",
        "                attention_mask = b_input_mask\n",
        "            )\n",
        "\n",
        "        logits = outputs.logits\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.numpy()\n",
        "        \n",
        "        #predictions.append(logits)\n",
        "        #true_labels.append(label_ids)\n",
        "        predictions.extend(list(np.argmax(logits, axis=1).flatten()))\n",
        "        true_labels.extend(list(label_ids))\n",
        "    \n",
        "    print('DONE.')\n",
        "\n",
        "    return predictions, true_labels\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrH3biqlpGgY"
      },
      "source": [
        "def save_checkpoint(path, model, optimizer, epoch, loss):\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss\n",
        "        }, path)\n",
        "\n",
        "\n",
        "def save_model(path, model):\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "\n",
        "def load_checkpoint(path):\n",
        "    checkpoint = torch.load(path)\n",
        "    return checkpoint['model_state_dict'], checkpoint['optimizer_state_dict'], checkpoint['epoch'], checkpoint['loss']\n",
        "\n",
        "\n",
        "def load_model(path):\n",
        "    return torch.load(path)\n",
        "\n",
        "\n",
        "def select_device():\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        print('No GPU available, using the CPU instead.')\n",
        "        device = torch.device(\"cpu\")\n",
        "    \n",
        "    return device\n",
        "\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdo8m-Qa900i"
      },
      "source": [
        "# Performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwkR6pndJUjz"
      },
      "source": [
        "def avg_accuracy(predictions,labels):\n",
        "    return sum(1 for i, j in zip(predictions, labels) if i == j) / len(predictions) \n",
        "\n",
        "def round_to_percentages(value):\n",
        "    return round(round(value, 4) * 100, 2)\n",
        "\n",
        "def majority_class(data):\n",
        "    elements_count = {}\n",
        "    for element in data:\n",
        "        if element not in elements_count:\n",
        "            elements_count[element] = 0\n",
        "        elements_count[element] += 1\n",
        "    maximum = max(elements_count, key=elements_count.get)\n",
        "    return elements_count[maximum] / len(data)\n",
        "\n",
        "def print_performance_metrics(predicted, true):\n",
        "    matrix = {}\n",
        "    labels = sorted(list(set(true)))\n",
        "\n",
        "    for t in labels:\n",
        "        for p in labels:\n",
        "            matrix[(t, p)] = sum([1 for i, j in zip(true, predicted) if i == t and j == p]) / len(true)\n",
        "\n",
        "    print()\n",
        "    print(\"Confusion Matrix\")\n",
        "    print(\"Rows - Actual\")\n",
        "    print(\"Columns - Predicted\")\n",
        "    print()\n",
        "\n",
        "    print((\"{:>3}\"+\" | \"+\"{:>6}\"*len(labels)+\" | \").format(\" \", *[p for p in labels]))\n",
        "\n",
        "    print(\"-\" * (3 + 3 + 6 * len(labels) + 3 + 6))\n",
        "\n",
        "    for t in labels:\n",
        "        print((\"{:>3}\"+\" | \"+\"{:>6.2f}\"*len(labels)+\" | \"+\"{:>6.2f}\").format(t, *[round_to_percentages(matrix[(t, p)]) for p in labels], round_to_percentages(sum([matrix[(t, p)] for p in labels]))))\n",
        "\n",
        "    print(\"-\" * (3 + 3 + 6 * len(labels) + 3 + 6))\n",
        "\n",
        "    print((\"{:>3}\"+\" | \"+\"{:>6.2f}\"*len(labels)+\" | \").format(\" \", *[round_to_percentages(sum([matrix[(t, p)] for t in labels])) for p in labels]))\n",
        "    \n",
        "    print()\n",
        "    print(\"{:<35}:{:>8.4f}\".format(\"Majority Class\", round(majority_class(true), 4)))\n",
        "    print(\"{:<35}:{:>8.4f}\".format(\"Accuracy\", round(avg_accuracy(predicted, true), 4)))\n",
        "    print()\n",
        "\n",
        "    if len(labels) == 2:\n",
        "        sensitivity = matrix[(labels[0], labels[0])] / (matrix[(labels[0], labels[0])] + matrix[(labels[0], labels[1])])\n",
        "        specificity = matrix[(labels[1], labels[1])] / (matrix[(labels[1], labels[1])] + matrix[(labels[1], labels[0])])\n",
        "        positive_predictive = matrix[(labels[0], labels[0])] / (matrix[(labels[0], labels[0])] + matrix[(labels[1], labels[0])])\n",
        "        negative_predictive = matrix[(labels[1], labels[1])] / (matrix[(labels[1], labels[1])] + matrix[(labels[0], labels[1])])\n",
        "        f1_score = 2 * ((positive_predictive * sensitivity) / (positive_predictive + sensitivity))\n",
        "\n",
        "        print(\"{:<35}:{:>8.4f}\".format(\"Sensitivity, Recall\", round(sensitivity, 4)))\n",
        "        print(\"{:<35}:{:>8.4f}\".format(\"Specificity\", round(specificity, 4)))\n",
        "        print(\"{:<35}:{:>8.4f}\".format(\"Positive Predictive, Precision\", round(positive_predictive, 4)))\n",
        "        print(\"{:<35}:{:>8.4f}\".format(\"Negative Predictive\", round(negative_predictive, 4)))\n",
        "        print(\"{:<35}:{:>8.4f}\".format(\"F1 Score\", round(f1_score, 4)))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cUR_wcTC5-p"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71eMX--LiLvU",
        "outputId": "e4bc0477-9ea6-4965-d280-25652b60e5fd"
      },
      "source": [
        "import spacy\n",
        "import re\n",
        "import classla\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "classla.download('sl')\n",
        "classla.download('sl', type='nonstandard')\n",
        "\n",
        "nlp_eng = spacy.load(\"en_core_web_sm\", disable=['tagger', 'parser', 'ner'])\n",
        "eng_stopwords = set(nlp_eng.Defaults.stop_words)\n",
        "slo_stopwords = set(stopwords.words('slovene'))\n",
        "\n",
        "def eng_preprocessing(text, remove_stopwords=True, do_lemmatization=True):\n",
        "\n",
        "    text = base_preprocessing(text)\n",
        "\n",
        "    tokens = []\n",
        "\n",
        "    # split text to single words\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    lemmer = WordNetLemmatizer()\n",
        "\n",
        "    # remove stopwords and words with length 1\n",
        "    for word in words:\n",
        "        if not remove_stopwords or word not in eng_stopwords:\n",
        "            if do_lemmatization:\n",
        "                word = lemmer.lemmatize(word)\n",
        "            tokens.append(word)\n",
        "\n",
        "    # convert tokens back to text\n",
        "    preprocessed_text = ' '.join([str(element) for element in tokens])\n",
        "    return preprocessed_text\n",
        "\n",
        "def slo_preprocessing(dataset, remove_stopwords=True, do_lemmatization=True):\n",
        "\n",
        "    # do base proccesing\n",
        "    dataset['preprocessed'] = dataset['Text'].apply(base_preprocessing)\n",
        "\n",
        "    # create pipelines\n",
        "    tokenizer = classla.Pipeline('sl', processors='tokenize', type='nonstandard', logging_level='WARN')\n",
        "    lemmatizer = classla.Pipeline('sl', processors='tokenize, lemma', type='nonstandard', logging_level='WARN')\n",
        "\n",
        "    # do tokenization\n",
        "    documents = '\\n'.join(dataset['preprocessed'].values)\n",
        "    out_docs = tokenizer(documents)\n",
        "\n",
        "    for i, sentence in enumerate(out_docs.sentences):\n",
        "        #print(\"DOCUMENT\")\n",
        "        seq = []\n",
        "        for word in sentence.words:\n",
        "            if not remove_stopwords or word.text not in slo_stopwords:\n",
        "                seq.append(word.text)\n",
        "\n",
        "        dataset.at[i, 'preprocessed'] = ' '.join(seq)\n",
        "\n",
        "    # do lemmatization\n",
        "    if do_lemmatization:\n",
        "        documents = '\\n'.join(dataset['preprocessed'].values)\n",
        "        out_docs = lemmatizer(documents)\n",
        "        \n",
        "        for i, sentence in enumerate(out_docs.sentences):\n",
        "            dataset.at[i, 'preprocessed'] = ' '.join(word.lemma for word in sentence.words)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def base_preprocessing(text):\n",
        "\n",
        "    EMOJI_PATTERN = re.compile(\n",
        "        \"([\"\n",
        "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
        "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
        "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
        "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
        "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
        "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
        "        \"])\"\n",
        "    )\n",
        "    text = re.sub(EMOJI_PATTERN,\"\",text)\n",
        "    # remove (twitter) urls\n",
        "    text = re.sub(r\"http://t.co/[a-zA-Z0-9čČšŠžŽ]+\", \"\", text)\n",
        "    text = re.sub(r\"https://t.co/[a-zA-Z0-9čČšŠžŽ]+\", \"\", text)\n",
        "\n",
        "    # remove all hashtags or @name Mentions (Usernames only allowed to includes characters A-Z, 0-9 and underscores)\n",
        "    text = re.sub(r\"[@#][a-zA-Z0-9_čČšŠžŽ]+\", \"\", text)\n",
        "\n",
        "    # remove non alphabetical characters\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\sčČšŠžŽ]\", \"\", text)\n",
        "\n",
        "    # remove multiple white spaces\n",
        "    text = re.sub(' +', ' ', text)\n",
        "\n",
        "    # convert all letters to lower case\n",
        "    text = text.lower()\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def run_dataset_preparation(dataset, lang=\"eng\", remove_stopwords=True, do_lemmatization=True):\n",
        "\n",
        "    dataset = dataset.dropna(how='any', axis=0)\n",
        "    if lang == \"eng\":\n",
        "        dataset['preprocessed'] = dataset['Text'].apply(eng_preprocessing, remove_stopwords=remove_stopwords, do_lemmatization=do_lemmatization)\n",
        "    elif lang == \"slo\":\n",
        "        dataset = slo_preprocessing(dataset, remove_stopwords=remove_stopwords, do_lemmatization=do_lemmatization)\n",
        "\n",
        "    x,y = dataset['preprocessed'], dataset['Label']\n",
        "    data = (x,y)\n",
        "    return data"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/clarinsi/classla-resources/main/resources_1.0.0.json: 10.3kB [00:00, 3.14MB/s]                   \n",
            "2021-04-22 17:51:56 INFO: Downloading these customized packages for language: sl (Slovenian)...\n",
            "========================\n",
            "| Processor | Package  |\n",
            "------------------------\n",
            "| tokenize  | standard |\n",
            "| pos       | standard |\n",
            "| lemma     | standard |\n",
            "| depparse  | standard |\n",
            "| ner       | standard |\n",
            "| pretrain  | standard |\n",
            "========================\n",
            "\n",
            "2021-04-22 17:51:57 INFO: File exists: /root/classla_resources/sl/pos/standard.pt.\n",
            "2021-04-22 17:51:57 INFO: File exists: /root/classla_resources/sl/lemma/standard.pt.\n",
            "2021-04-22 17:51:57 INFO: File exists: /root/classla_resources/sl/depparse/standard.pt.\n",
            "2021-04-22 17:51:57 INFO: File exists: /root/classla_resources/sl/ner/standard.pt.\n",
            "2021-04-22 17:51:57 INFO: File exists: /root/classla_resources/sl/pretrain/standard.pt.\n",
            "2021-04-22 17:51:58 INFO: Finished downloading models and saved to /root/classla_resources.\n",
            "Downloading https://raw.githubusercontent.com/clarinsi/classla-resources/main/resources_1.0.0.json: 10.3kB [00:00, 2.87MB/s]                   \n",
            "2021-04-22 17:51:58 INFO: Downloading these customized packages for language: sl (Slovenian)...\n",
            "===========================\n",
            "| Processor | Package     |\n",
            "---------------------------\n",
            "| tokenize  | nonstandard |\n",
            "| pos       | nonstandard |\n",
            "| lemma     | nonstandard |\n",
            "| depparse  | standard    |\n",
            "| ner       | nonstandard |\n",
            "| pretrain  | standard    |\n",
            "===========================\n",
            "\n",
            "2021-04-22 17:51:58 INFO: File exists: /root/classla_resources/sl/pos/nonstandard.pt.\n",
            "2021-04-22 17:51:58 INFO: File exists: /root/classla_resources/sl/lemma/nonstandard.pt.\n",
            "2021-04-22 17:51:58 INFO: File exists: /root/classla_resources/sl/depparse/standard.pt.\n",
            "2021-04-22 17:51:58 INFO: File exists: /root/classla_resources/sl/ner/nonstandard.pt.\n",
            "2021-04-22 17:51:59 INFO: File exists: /root/classla_resources/sl/pretrain/standard.pt.\n",
            "2021-04-22 17:51:59 INFO: Finished downloading models and saved to /root/classla_resources.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTNtYoht-Den"
      },
      "source": [
        "# Other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9W9YAKe44xX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def distribution_dataset(data):\n",
        "    class_distribution = {}\n",
        "    for element in data:\n",
        "        if element not in class_distribution:\n",
        "            class_distribution[element] = 0\n",
        "        class_distribution[element] += 1\n",
        "    return class_distribution"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itIORIUu-MpJ"
      },
      "source": [
        "# Binary Eng classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z48_4PEW_34D"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugdgb93AqdAV"
      },
      "source": [
        "binary_data = pd.read_csv('drive/MyDrive/Data/Eng/Binary/data.csv')\n",
        "x,y = run_dataset_preparation(binary_data, \"eng\", remove_stopwords=True, do_lemmatization=True)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbPWMpV23UVn",
        "outputId": "5c6d11d0-63a9-48be-80ac-81e6b9968bb1"
      },
      "source": [
        "model = setup_classifier(\n",
        "    model_name = \"drive/MyDrive/classifiers/bert/CroSloEngual\",\n",
        "    num_labels = 2\n",
        ")\n",
        "\n",
        "# model.load_state_dict(bert.load_model(\"models/m1.pt\"))\n",
        "\n",
        "dataset = setup_data(\n",
        "    model_name = \"drive/MyDrive/classifiers/bert/CroSloEngual\",\n",
        "    x = x,\n",
        "    y = y,\n",
        "    do_lower_case = False,\n",
        "    max_length = 180\n",
        ")\n",
        "\n",
        "test_ratio = 0.8\n",
        "train_size = int(test_ratio * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at drive/MyDrive/classifiers/bert/CroSloEngual were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/classifiers/bert/CroSloEngual and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTN9KIt0ASOt"
      },
      "source": [
        "## Train dataset class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "11ZtjhbhA821",
        "outputId": "79ae25e9-54be-428a-a61e-45dc0055303f"
      },
      "source": [
        "class_distribution = distribution_dataset([e[2].item() for e in list(train_dataset)])\n",
        "print(class_distribution)\n",
        "y = list(class_distribution.keys())\n",
        "x = list(class_distribution.values())\n",
        "plt.bar(y, x, color=\"tab:blue\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 34320, 1: 26243}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 2 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HJh2OzQAb7c"
      },
      "source": [
        "## Test dataset class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "8ECSBRR5BVIv",
        "outputId": "2b2bbe49-ed55-4e20-9fc6-d637031abc99"
      },
      "source": [
        "class_distribution = distribution_dataset([e[2].item() for e in list(test_dataset)])\n",
        "print(class_distribution)\n",
        "y = list(class_distribution.keys())\n",
        "x = list(class_distribution.values())\n",
        "plt.bar(y, x, color=\"tab:orange\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 8511, 1: 6630}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 2 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWG0lEQVR4nO3df5Bd5X3f8fcnKODYSUAyG5VI1JLHajw4U2OyA8T2pLXlCEE6Fp3aFE9Sb6g6Slqaxm1nGqj/kIPN1E47JWFa09GAYuGmYELjQU1oyFrgyXRcfiw2xoCNtYAJUgFtkFDqMCYW+faP+6x9kXe1d9Hdu1LP+zVz5z7nOc8593sOy+cenXvuPakqJEnd8EPLXYAkaXQMfUnqEENfkjrE0JekDjH0JalDVix3Acdy5pln1rp165a7DEk6qTz44IN/XlVjc807oUN/3bp1TE1NLXcZknRSSfL0fPM8vSNJHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdckJ/I/e4fez05a5AJ6qPHV7uCqRl4ZG+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhA4V+kn+Z5NEkjyS5JcnrkqxPcl+S6SSfS3JqG3tam55u89f1refq1v94kouWZpMkSfNZMPSTrAH+BTBeVT8NnAJcDnwKuK6q3gIcAra2RbYCh1r/dW0cSc5py70N2Ax8Oskpw90cSdKxDHp6ZwXwI0lWAK8HngXeC9ze5u8CLm3tLW2aNn9jkrT+W6vq5ap6CpgGzj/+TZAkDWrB0K+q/cB/AP6MXtgfBh4EXqyqI23YPmBNa68BnmnLHmnj39jfP8cy35NkW5KpJFMzMzOvZZskSfMY5PTOSnpH6euBnwTeQO/0zJKoqh1VNV5V42NjY0v1MpLUSYOc3nkf8FRVzVTVd4E/AN4FnNFO9wCsBfa39n7gbIA2/3Tghf7+OZaRJI3AIKH/Z8CFSV7fzs1vBB4D7gE+0MZMAHe09u42TZt/d1VV67+8Xd2zHtgA3D+czZAkDWLB39OvqvuS3A58GTgCfAXYAfwRcGuST7S+m9oiNwGfTTINHKR3xQ5V9WiS2+i9YRwBrqyqV4a8PZKkYxjoJipVtR3YflT3k8xx9U1VfQf44DzruRa4dpE1SpKGxG/kSlKHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1yCD3yP2pJA/1Pf4iyUeSrEoymWRve17ZxifJ9Ummkzyc5Ly+dU208XuTTMz/qpKkpbBg6FfV41V1blWdC/wM8BLweeAqYE9VbQD2tGmAi+ndCnEDsA24ASDJKno3YrmA3s1Xts++UUiSRmOxp3c2Ak9U1dPAFmBX698FXNraW4Cbq+deejdQPwu4CJisqoNVdQiYBDYf9xZIkga22NC/HLiltVdX1bOt/RywurXXAM/0LbOv9c3X/ypJtiWZSjI1MzOzyPIkSccycOgnORV4P/D7R8+rqgJqGAVV1Y6qGq+q8bGxsWGsUpLULOZI/2Lgy1X1fJt+vp22oT0faP37gbP7llvb+ubrlySNyGJC/0N8/9QOwG5g9gqcCeCOvv4Pt6t4LgQOt9NAdwGbkqxsH+Buan2SpBFZMcigJG8Afh74lb7uTwK3JdkKPA1c1vrvBC4Bpuld6XMFQFUdTPJx4IE27pqqOnjcWyBJGthAoV9Vfwm88ai+F+hdzXP02AKunGc9O4Gdiy9TkjQMfiNXkjrE0JekDjH0JalDBjqnL2mJfOz05a5AJ6qPHV6S1XqkL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdchAoZ/kjCS3J/lGkq8n+dkkq5JMJtnbnle2sUlyfZLpJA8nOa9vPRNt/N4kE/O/oiRpKQx6pP87wB9X1VuBtwNfB64C9lTVBmBPm4beDdQ3tMc24AaAJKuA7cAFwPnA9tk3CknSaCwY+klOB34OuAmgqv6qql4EtgC72rBdwKWtvQW4uXruBc5IchZwETBZVQer6hAwCWwe6tZIko5pkCP99cAM8LtJvpLkxnaj9NVV9Wwb8xywurXXAM/0Lb+v9c3X/ypJtiWZSjI1MzOzuK2RJB3TIKG/AjgPuKGq3gH8Jd8/lQN872boNYyCqmpHVY1X1fjY2NgwVilJagYJ/X3Avqq6r03fTu9N4Pl22ob2fKDN3w+c3bf82tY3X78kaUQWDP2qeg54JslPta6NwGPAbmD2CpwJ4I7W3g18uF3FcyFwuJ0GugvYlGRl+wB3U+uTJI3IoPfI/TXg95KcCjwJXEHvDeO2JFuBp4HL2tg7gUuAaeClNpaqOpjk48ADbdw1VXVwKFshSRrIQKFfVQ8B43PM2jjH2AKunGc9O4GdiylQkjQ8fiNXkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDBgr9JN9K8rUkDyWZan2rkkwm2dueV7b+JLk+yXSSh5Oc17eeiTZ+b5KJ+V5PkrQ0FnOk/56qOreqZm+mchWwp6o2AHv4/s3SLwY2tMc24AbovUkA24ELgPOB7bNvFJKk0Tie0ztbgF2tvQu4tK//5uq5Fzij3Tj9ImCyqg5W1SFgEth8HK8vSVqkQUO/gD9J8mCSba1vdbvhOcBzwOrWXgM807fsvtY3X/+rJNmWZCrJ1MzMzIDlSZIGMeiN0d9dVfuT/AQwmeQb/TOrqpLUMAqqqh3ADoDx8fGhrFOS1DPQkX5V7W/PB4DP0zsn/3w7bUN7PtCG7wfO7lt8beubr1+SNCILhn6SNyT5sdk2sAl4BNgNzF6BMwHc0dq7gQ+3q3guBA6300B3AZuSrGwf4G5qfZKkERnk9M5q4PNJZsf/t6r64yQPALcl2Qo8DVzWxt8JXAJMAy8BVwBU1cEkHwceaOOuqaqDQ9sSSdKCFgz9qnoSePsc/S8AG+foL+DKeda1E9i5+DIlScPgN3IlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjpk4NBPckqSryT5wza9Psl9SaaTfC7Jqa3/tDY93eav61vH1a3/8SQXDXtjJEnHtpgj/V8Hvt43/Snguqp6C3AI2Nr6twKHWv91bRxJzgEuB94GbAY+neSU4ytfkrQYA4V+krXALwA3tukA7wVub0N2AZe29pY2TZu/sY3fAtxaVS9X1VP0bqd4/jA2QpI0mEGP9H8b+DfAX7fpNwIvVtWRNr0PWNPaa4BnANr8w2389/rnWOZ7kmxLMpVkamZmZhGbIklayIKhn+TvAQeq6sER1ENV7aiq8aoaHxsbG8VLSlJnLHhjdOBdwPuTXAK8Dvhx4HeAM5KsaEfza4H9bfx+4GxgX5IVwOnAC339s/qXkSSNwIJH+lV1dVWtrap19D6IvbuqfhG4B/hAGzYB3NHau9s0bf7dVVWt//J2dc96YANw/9C2RJK0oEGO9OfzG8CtST4BfAW4qfXfBHw2yTRwkN4bBVX1aJLbgMeAI8CVVfXKcby+JGmRFhX6VfVF4Iut/SRzXH1TVd8BPjjP8tcC1y62SEnScPiNXEnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDBrkx+uuS3J/kq0keTfKbrX99kvuSTCf5XJJTW/9pbXq6zV/Xt66rW//jSS5aqo2SJM1tkCP9l4H3VtXbgXOBzUkuBD4FXFdVbwEOAVvb+K3AodZ/XRtHknPo3TrxbcBm4NNJThnmxkiSjm2QG6NXVX27Tf5wexTwXuD21r8LuLS1t7Rp2vyNSdL6b62ql6vqKWCaOW63KElaOgOd009ySpKHgAPAJPAE8GJVHWlD9gFrWnsN8AxAm38YeGN//xzL9L/WtiRTSaZmZmYWv0WSpHkNFPpV9UpVnQuspXd0/talKqiqdlTVeFWNj42NLdXLSFInLerqnap6EbgH+FngjCQr2qy1wP7W3g+cDdDmnw680N8/xzKSpBEY5OqdsSRntPaPAD8PfJ1e+H+gDZsA7mjt3W2aNv/uqqrWf3m7umc9sAG4f1gbIkla2IqFh3AWsKtdafNDwG1V9YdJHgNuTfIJ4CvATW38TcBnk0wDB+ldsUNVPZrkNuAx4AhwZVW9MtzNkSQdy4KhX1UPA++Yo/9J5rj6pqq+A3xwnnVdC1y7+DIlScPgN3IlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjpkkDtnnZ3kniSPJXk0ya+3/lVJJpPsbc8rW3+SXJ9kOsnDSc7rW9dEG783ycR8rylJWhqDHOkfAf51VZ0DXAhcmeQc4CpgT1VtAPa0aYCL6d0KcQOwDbgBem8SwHbgAno3X9k++0YhSRqNBUO/qp6tqi+39v+ld3/cNcAWYFcbtgu4tLW3ADdXz730bqB+FnARMFlVB6vqEDAJbB7q1kiSjmlR5/STrKN368T7gNVV9Wyb9RywurXXAM/0Lbav9c3Xf/RrbEsylWRqZmZmMeVJkhYwcOgn+VHgvwMfqaq/6J9XVQXUMAqqqh1VNV5V42NjY8NYpSSpGSj0k/wwvcD/var6g9b9fDttQ3s+0Pr3A2f3Lb629c3XL0kakUGu3glwE/D1qvqPfbN2A7NX4EwAd/T1f7hdxXMhcLidBroL2JRkZfsAd1PrkySNyIoBxrwL+EfA15I81Pr+LfBJ4LYkW4GngcvavDuBS4Bp4CXgCoCqOpjk48ADbdw1VXVwKFshSRrIgqFfVf8LyDyzN84xvoAr51nXTmDnYgqUJA2P38iVpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeqQQe6ctTPJgSSP9PWtSjKZZG97Xtn6k+T6JNNJHk5yXt8yE2383iQTc72WJGlpDXKk/xlg81F9VwF7qmoDsKdNA1wMbGiPbcAN0HuTALYDFwDnA9tn3ygkSaOzYOhX1Z8CR9/WcAuwq7V3AZf29d9cPfcCZ7Sbpl8ETFbVwao6BEzyg28kkqQl9lrP6a9uNzsHeA5Y3dprgGf6xu1rffP1/4Ak25JMJZmamZl5jeVJkuZy3B/ktnvi1hBqmV3fjqoar6rxsbGxYa1WksRrD/3n22kb2vOB1r8fOLtv3NrWN1+/JGmEXmvo7wZmr8CZAO7o6/9wu4rnQuBwOw10F7Apycr2Ae6m1idJGqEVCw1Icgvwd4Ezk+yjdxXOJ4HbkmwFngYua8PvBC4BpoGXgCsAqupgko8DD7Rx11TV0R8OS5KW2IKhX1UfmmfWxjnGFnDlPOvZCexcVHWSpKHyG7mS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtSh4w89JNsTvJ4kukkV4369SWpy0Ya+klOAf4zcDFwDvChJOeMsgZJ6rJRH+mfD0xX1ZNV9VfArcCWEdcgSZ214D1yh2wN8Ezf9D7ggv4BSbYB29rkt5M8PqLaXqszgT9f7iIGYJ39fjPDWIv7dLhOljphFLUe39/om+abMerQX1BV7QB2LHcdg0oyVVXjy13HQqxz+E6WWq1z+E6mWo826tM7+4Gz+6bXtj5J0giMOvQfADYkWZ/kVOByYPeIa5Ckzhrp6Z2qOpLknwN3AacAO6vq0VHWsAROllNR1jl8J0ut1jl8J1Otr5KqWu4aJEkj4jdyJalDDH1J6hBDfwBJViWZTLK3Pa+cY8y5Sf53kkeTPJzkH/bN+0ySp5I81B7nDrm+Y/60RZLTknyuzb8vybq+eVe3/seTXDTMul5Dnf8qyWNt/+1J8qa+ea/07b8l/fB/gDp/OclMXz3/pG/eRPs72ZtkYpnrvK6vxm8mebFv3ij3584kB5I8Ms/8JLm+bcfDSc7rmzfK/blQnb/Y6vtaki8leXvfvG+1/oeSTC1lncetqnws8AB+C7iqta8CPjXHmL8FbGjtnwSeBc5o058BPrBEtZ0CPAG8GTgV+CpwzlFj/hnwX1r7cuBzrX1OG38asL6t55RlrPM9wOtb+5/O1tmmvz2i/9aD1PnLwH+aY9lVwJPteWVrr1yuOo8a/2v0LpwY6f5sr/VzwHnAI/PMvwT4n0CAC4H7Rr0/B6zznbOvT++nZO7rm/ct4MxR7dPjeXikP5gtwK7W3gVcevSAqvpmVe1t7f8DHADGRlDbID9t0V//7cDGJGn9t1bVy1X1FDDd1rcsdVbVPVX1Upu8l973OEbteH4q5CJgsqoOVtUhYBLYfILU+SHgliWq5Ziq6k+Bg8cYsgW4uXruBc5Ichaj3Z8L1llVX2p1wPL9fR43Q38wq6vq2dZ+Dlh9rMFJzqd39PVEX/e17Z+G1yU5bYi1zfXTFmvmG1NVR4DDwBsHXHaUdfbbSu/ob9brkkwluTfJD7zpDtGgdf6D9t/z9iSzXzg8IfdnO022Hri7r3tU+3MQ823LKPfnYh3991nAnyR5sP2UzAnrhPsZhuWS5AvA35hj1kf7J6qqksx7nWs7QvksMFFVf926r6b3ZnEqvet7fwO4Zhh1//8oyS8B48Df6et+U1XtT/Jm4O4kX6uqJ+Zew5L7H8AtVfVykl+h96+o9y5TLYO4HLi9ql7p6zuR9udJJcl76IX+u/u63932508Ak0m+0f7lcMLxSL+pqvdV1U/P8bgDeL6F+WyoH5hrHUl+HPgj4KPtn6mz6362/dP1ZeB3Ge4plEF+2uJ7Y5KsAE4HXhhw2VHWSZL30XujfX/bXwBU1f72/CTwReAdy1VnVb3QV9uNwM8Muuwo6+xzOUed2hnh/hzEfNtywv1sS5K/Te+/+ZaqemG2v29/HgA+z9KdJj1+y/2hwsnwAP49r/4g97fmGHMqsAf4yBzzzmrPAX4b+OQQa1tB7wOu9Xz/A723HTXmSl79Qe5trf02Xv1B7pMs3Qe5g9T5DnqnxDYc1b8SOK21zwT2cowPLUdQ51l97b8P3Nvaq4CnWr0rW3vVctXZxr2V3oeMWY792fea65j/A9Jf4NUf5N4/6v05YJ1/k97nXu88qv8NwI/1tb8EbF7KOo9rG5e7gJPhQe/89572P8cXZv/w6J2CuLG1fwn4LvBQ3+PcNu9u4GvAI8B/BX50yPVdAnyzBeZHW9819I6WAV4H/H77g70feHPfsh9tyz0OXLzE+3GhOr8APN+3/3a3/ne2/ffV9rx1mev8d8CjrZ57gLf2LfuP236eBq5Yzjrb9Mc46iBjGfbnLfSuZvsuvfPyW4FfBX61zQ+9mys90eoZX6b9uVCdNwKH+v4+p1r/m9u+/Gr7u/joUtZ5vA9/hkGSOsRz+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR3y/wD5yewUTABBVAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_9Vgtcy_9cR"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzcU0XMR3Yor"
      },
      "source": [
        "model, stats = train_classifier(\n",
        "    model = model,\n",
        "    dataset = train_dataset,\n",
        "    validation_ratio = 0.9,\n",
        "    batch_size = 32,\n",
        "    freeze_embeddings_layer = False,\n",
        "    freeze_encoder_layers = 0,\n",
        "    epochs = 1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmPslDtRAAlh"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzVHRZEXySqO",
        "outputId": "c84684d8-2b16-43d4-cd71-eb660000eead"
      },
      "source": [
        "predictions, true_labels = test_classifier(\n",
        "    model = model,\n",
        "    dataset = test_dataset,\n",
        "    batch_size = 32\n",
        ")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at drive/MyDrive/classifiers/bert/CroSloEngual were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/classifiers/bert/CroSloEngual and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of  1,704.    Elapsed: 0:00:36.\n",
            "  Batch    80  of  1,704.    Elapsed: 0:01:11.\n",
            "  Batch   120  of  1,704.    Elapsed: 0:01:48.\n",
            "  Batch   160  of  1,704.    Elapsed: 0:02:26.\n",
            "  Batch   200  of  1,704.    Elapsed: 0:03:03.\n",
            "  Batch   240  of  1,704.    Elapsed: 0:03:40.\n",
            "  Batch   280  of  1,704.    Elapsed: 0:04:18.\n",
            "  Batch   320  of  1,704.    Elapsed: 0:04:55.\n",
            "  Batch   360  of  1,704.    Elapsed: 0:05:33.\n",
            "  Batch   400  of  1,704.    Elapsed: 0:06:10.\n",
            "  Batch   440  of  1,704.    Elapsed: 0:06:47.\n",
            "  Batch   480  of  1,704.    Elapsed: 0:07:25.\n",
            "  Batch   520  of  1,704.    Elapsed: 0:08:02.\n",
            "  Batch   560  of  1,704.    Elapsed: 0:08:39.\n",
            "  Batch   600  of  1,704.    Elapsed: 0:09:17.\n",
            "  Batch   640  of  1,704.    Elapsed: 0:09:54.\n",
            "  Batch   680  of  1,704.    Elapsed: 0:10:32.\n",
            "  Batch   720  of  1,704.    Elapsed: 0:11:09.\n",
            "  Batch   760  of  1,704.    Elapsed: 0:11:46.\n",
            "  Batch   800  of  1,704.    Elapsed: 0:12:24.\n",
            "  Batch   840  of  1,704.    Elapsed: 0:13:01.\n",
            "  Batch   880  of  1,704.    Elapsed: 0:13:39.\n",
            "  Batch   920  of  1,704.    Elapsed: 0:14:16.\n",
            "  Batch   960  of  1,704.    Elapsed: 0:14:54.\n",
            "  Batch 1,000  of  1,704.    Elapsed: 0:15:31.\n",
            "  Batch 1,040  of  1,704.    Elapsed: 0:16:08.\n",
            "  Batch 1,080  of  1,704.    Elapsed: 0:16:46.\n",
            "  Batch 1,120  of  1,704.    Elapsed: 0:17:23.\n",
            "  Batch 1,160  of  1,704.    Elapsed: 0:18:00.\n",
            "  Batch 1,200  of  1,704.    Elapsed: 0:18:38.\n",
            "  Batch 1,240  of  1,704.    Elapsed: 0:19:15.\n",
            "  Batch 1,280  of  1,704.    Elapsed: 0:19:53.\n",
            "  Batch 1,320  of  1,704.    Elapsed: 0:20:30.\n",
            "  Batch 1,360  of  1,704.    Elapsed: 0:21:07.\n",
            "  Batch 1,400  of  1,704.    Elapsed: 0:21:45.\n",
            "  Batch 1,440  of  1,704.    Elapsed: 0:22:22.\n",
            "  Batch 1,480  of  1,704.    Elapsed: 0:22:59.\n",
            "  Batch 1,520  of  1,704.    Elapsed: 0:23:37.\n",
            "  Batch 1,560  of  1,704.    Elapsed: 0:24:14.\n",
            "  Batch 1,600  of  1,704.    Elapsed: 0:24:52.\n",
            "  Batch 1,640  of  1,704.    Elapsed: 0:25:29.\n",
            "  Batch 1,680  of  1,704.    Elapsed: 0:26:07.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:26:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "  Validation Loss: 0.24\n",
            "  Validation took: 0:01:08\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:27:36 (h:mm:ss)\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "\n",
            "Running Prediction...\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP2iSlOwAGFe"
      },
      "source": [
        "## Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsmDx5DXIlV4",
        "outputId": "eef8a47c-3bc1-4a72-840a-6f6fd94ee24f"
      },
      "source": [
        "print_performance_metrics(predictions, true_labels)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion Matrix\n",
            "Rows - Actual\n",
            "Columns - Predicted\n",
            "\n",
            "    |      0     1 | \n",
            "---------------------------\n",
            "  0 |  53.52  3.63 |  57.15\n",
            "  1 |   4.73 38.12 |  42.85\n",
            "---------------------------\n",
            "    |  58.25 41.75 | \n",
            "\n",
            "Majority Class                     :  0.5715\n",
            "Accuracy                           :  0.9164\n",
            "\n",
            "Sensitivity, Recall                :  0.9364\n",
            "Specificity                        :  0.8896\n",
            "Positive Predictive, Precision     :  0.9188\n",
            "Negative Predictive                :  0.9130\n",
            "F1 Score                           :  0.9275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSanatpqKcOz"
      },
      "source": [
        "**Saving model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGNAQXvpzH2j"
      },
      "source": [
        "save_model(\"drive/MyDrive/models/binary.pt\", model)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwFfPKXW-eVr"
      },
      "source": [
        "# Multiclass Eng classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPxOSL2D_N4R"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkb5Ox29KEkS"
      },
      "source": [
        "multiclass_data = pd.read_csv('drive/MyDrive/Data/Eng/Multiclass/data.csv')\n",
        "x,y = run_dataset_preparation(multiclass_data, \"eng\", remove_stopwords=True, do_lemmatization=True)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qQq7zVFKQup",
        "outputId": "9cf4cda1-2ad6-4ec4-c2ba-958f545e1640"
      },
      "source": [
        "model = setup_classifier(\n",
        "    model_name = \"drive/MyDrive/classifiers/bert/CroSloEngual\",\n",
        "    num_labels = 6\n",
        ")\n",
        "\n",
        "# model.load_state_dict(bert.load_model(\"models/m1.pt\"))\n",
        "\n",
        "dataset = setup_data(\n",
        "    model_name = \"drive/MyDrive/classifiers/bert/CroSloEngual\",\n",
        "    x = x,\n",
        "    y = y,\n",
        "    do_lower_case = False,\n",
        "    max_length = 180\n",
        ")\n",
        "\n",
        "test_ratio = 0.8\n",
        "train_size = int(test_ratio * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at drive/MyDrive/classifiers/bert/CroSloEngual were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/classifiers/bert/CroSloEngual and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gBS2fvo8_Z_"
      },
      "source": [
        "## Train dataset class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "C1Da6VhT5WrN",
        "outputId": "607c901f-26d4-4a0d-d272-3b85eb101553"
      },
      "source": [
        "class_distribution = distribution_dataset([e[2].item() for e in list(train_dataset)])\n",
        "print(class_distribution)\n",
        "y = list(class_distribution.keys())\n",
        "x = list(class_distribution.values())\n",
        "plt.bar(y, x, color=\"tab:blue\")"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 34261, 2: 5184, 4: 534, 3: 3009, 1: 1056, 5: 287}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 6 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATA0lEQVR4nO3df4xdZ33n8fendgIRlLVDZiPLNuuoWK0MUk2YOl5RVWwQziRUdSpRlEhLLJTFXeFIoK22OP0n5Uek8EfJbiSI5DbeOLsUY/FDsYKpawWvUKRN4jGYJE7IZjYExZaJpzg/iNAGOfvdP+7j9ta9M3M9dzx3PH6/pKN7zvc859znEcKfOec89yRVhSTp4vYbw+6AJGn4DANJkmEgSTIMJEkYBpIkYOmwOzBbV1xxRa1Zs2bY3ZCkC8rhw4f/oapGzq5fsGGwZs0axsfHh90NSbqgJPlZr7q3iSRJM4dBkrcmeTzJj5McTfK5Vr8/yU+THGnL+lZPknuSTCR5IsnVXefakuS5tmzpqr8/yZPtmHuS5HwMVpLUWz+3id4Arq2q15NcAjyS5Htt33+uqm+e1f56YG1brgHuBa5JcjlwBzAKFHA4yd6qerm1+STwGLAPGAO+hyRpXsx4ZVAdr7fNS9oy3TssNgMPtOMeBZYlWQFcBxyoqlMtAA4AY23fO6rq0eq8G+MB4MYBxiRJOkd9PTNIsiTJEeAknX/QH2u77my3gu5O8pZWWwm82HX4sVabrn6sR71XP7YmGU8yPjk52U/XJUl96CsMqurNqloPrAI2JHkvcDvwO8DvAZcDnz1vvfynfuyoqtGqGh0Z+RczoyRJs3ROs4mq6hXgIDBWVSfaraA3gP8GbGjNjgOruw5b1WrT1Vf1qEuS5kk/s4lGkixr65cBHwZ+0u7102b+3Ag81Q7ZC9zSZhVtBF6tqhPAfmBTkuVJlgObgP1t32tJNrZz3QI8OLfDlCRNp5/ZRCuAXUmW0AmPPVX1UJLvJxkBAhwB/mNrvw+4AZgAfgV8AqCqTiX5AnCotft8VZ1q658C7gcuozOLyJlEkjSPcqH+x21GR0drtr9AXrP9u3Pcm/Pjhbs+MuwuSFpkkhyuqtGz6/4CWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkkQfYZDkrUkeT/LjJEeTfK7Vr0ryWJKJJN9Icmmrv6VtT7T9a7rOdXurP5vkuq76WKtNJNk+98OUJE2nnyuDN4Brq+p3gfXAWJKNwJeAu6vq3cDLwK2t/a3Ay61+d2tHknXATcB7gDHgq0mWJFkCfAW4HlgH3NzaSpLmyYxhUB2vt81L2lLAtcA3W30XcGNb39y2afs/lCStvruq3qiqnwITwIa2TFTV81X1a2B3aytJmid9PTNof8EfAU4CB4D/A7xSVadbk2PAyra+EngRoO1/FXhnd/2sY6aq9+rH1iTjScYnJyf76bokqQ99hUFVvVlV64FVdP6S/53z2qup+7GjqkaranRkZGQYXZCkRemcZhNV1SvAQeDfAsuSLG27VgHH2/pxYDVA2/+vgF901886Zqq6JGme9DObaCTJsrZ+GfBh4Bk6ofDR1mwL8GBb39u2afu/X1XV6je12UZXAWuBx4FDwNo2O+lSOg+Z987F4CRJ/Vk6cxNWALvarJ/fAPZU1UNJngZ2J/ki8CPgvtb+PuC/J5kATtH5x52qOppkD/A0cBrYVlVvAiS5DdgPLAF2VtXRORuhJGlGM4ZBVT0BvK9H/Xk6zw/Orv9f4E+mONedwJ096vuAfX30V5J0HvgLZEmSYSBJMgwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJPsIgyeokB5M8neRokk+3+l8mOZ7kSFtu6Drm9iQTSZ5Ncl1XfazVJpJs76pfleSxVv9GkkvneqCSpKn1c2VwGvizqloHbAS2JVnX9t1dVevbsg+g7bsJeA8wBnw1yZIkS4CvANcD64Cbu87zpXaudwMvA7fO0fgkSX2YMQyq6kRV/bCt/xJ4Blg5zSGbgd1V9UZV/RSYADa0ZaKqnq+qXwO7gc1JAlwLfLMdvwu4cbYDkiSdu3N6ZpBkDfA+4LFWui3JE0l2JlneaiuBF7sOO9ZqU9XfCbxSVafPqvf6/q1JxpOMT05OnkvXJUnT6DsMkrwd+Bbwmap6DbgX+C1gPXAC+Kvz0sMuVbWjqkaranRkZOR8f50kXTSW9tMoySV0guBrVfVtgKp6qWv/XwMPtc3jwOquw1e1GlPUfwEsS7K0XR10t5ckzYN+ZhMFuA94pqq+3FVf0dXsj4Gn2vpe4KYkb0lyFbAWeBw4BKxtM4cupfOQeW9VFXAQ+Gg7fgvw4GDDkiSdi36uDD4AfBx4MsmRVvsLOrOB1gMFvAD8KUBVHU2yB3iazkykbVX1JkCS24D9wBJgZ1Udbef7LLA7yReBH9EJH0nSPJkxDKrqESA9du2b5pg7gTt71Pf1Oq6qnqcz20iSNAT+AlmSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJJEH2GQZHWSg0meTnI0yadb/fIkB5I81z6Xt3qS3JNkIskTSa7uOteW1v65JFu66u9P8mQ75p4kOR+DlST11s+VwWngz6pqHbAR2JZkHbAdeLiq1gIPt22A64G1bdkK3Aud8ADuAK4BNgB3nAmQ1uaTXceNDT40SVK/ZgyDqjpRVT9s678EngFWApuBXa3ZLuDGtr4ZeKA6HgWWJVkBXAccqKpTVfUycAAYa/veUVWPVlUBD3SdS5I0D87pmUGSNcD7gMeAK6vqRNv1c+DKtr4SeLHrsGOtNl39WI96r+/fmmQ8yfjk5OS5dF2SNI2+wyDJ24FvAZ+pqte697W/6GuO+/YvVNWOqhqtqtGRkZHz/XWSdNHoKwySXEInCL5WVd9u5ZfaLR7a58lWPw6s7jp8VatNV1/Voy5Jmif9zCYKcB/wTFV9uWvXXuDMjKAtwINd9VvarKKNwKvtdtJ+YFOS5e3B8SZgf9v3WpKN7btu6TqXJGkeLO2jzQeAjwNPJjnSan8B3AXsSXIr8DPgY23fPuAGYAL4FfAJgKo6leQLwKHW7vNVdaqtfwq4H7gM+F5bJEnzZMYwqKpHgKnm/X+oR/sCtk1xrp3Azh71ceC9M/VFknR++AtkSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEn2EQZKdSU4meaqr9pdJjic50pYbuvbdnmQiybNJruuqj7XaRJLtXfWrkjzW6t9IculcDlCSNLN+rgzuB8Z61O+uqvVt2QeQZB1wE/CedsxXkyxJsgT4CnA9sA64ubUF+FI717uBl4FbBxmQJOnczRgGVfUD4FSf59sM7K6qN6rqp8AEsKEtE1X1fFX9GtgNbE4S4Frgm+34XcCN5zgGSdKABnlmcFuSJ9ptpOWtthJ4savNsVabqv5O4JWqOn1WvackW5OMJxmfnJwcoOuSpG6zDYN7gd8C1gMngL+asx5No6p2VNVoVY2OjIzMx1dK0kVh6WwOqqqXzqwn+WvgobZ5HFjd1XRVqzFF/RfAsiRL29VBd3tJ0jyZ1ZVBkhVdm38MnJlptBe4KclbklwFrAUeBw4Ba9vMoUvpPGTeW1UFHAQ+2o7fAjw4mz5JkmZvxiuDJF8HPghckeQYcAfwwSTrgQJeAP4UoKqOJtkDPA2cBrZV1ZvtPLcB+4ElwM6qOtq+4rPA7iRfBH4E3Ddno5Mk9WXGMKiqm3uUp/wHu6ruBO7sUd8H7OtRf57ObCNJ0pD4C2RJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSfYRBkp1JTiZ5qqt2eZIDSZ5rn8tbPUnuSTKR5IkkV3cds6W1fy7Jlq76+5M82Y65J0nmepCSpOn1c2VwPzB2Vm078HBVrQUebtsA1wNr27IVuBc64QHcAVwDbADuOBMgrc0nu447+7skSefZjGFQVT8ATp1V3gzsauu7gBu76g9Ux6PAsiQrgOuAA1V1qqpeBg4AY23fO6rq0aoq4IGuc0mS5slsnxlcWVUn2vrPgSvb+krgxa52x1ptuvqxHvWekmxNMp5kfHJycpZdlySdbeAHyO0v+pqDvvTzXTuqarSqRkdGRubjKyXpojDbMHip3eKhfZ5s9ePA6q52q1ptuvqqHnVJ0jyabRjsBc7MCNoCPNhVv6XNKtoIvNpuJ+0HNiVZ3h4cbwL2t32vJdnYZhHd0nUuSdI8WTpTgyRfBz4IXJHkGJ1ZQXcBe5LcCvwM+Fhrvg+4AZgAfgV8AqCqTiX5AnCotft8VZ15KP0pOjOWLgO+1xZJ0jyaMQyq6uYpdn2oR9sCtk1xnp3Azh71ceC9M/VDknT++AtkSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEgOGQZIXkjyZ5EiS8Va7PMmBJM+1z+WtniT3JJlI8kSSq7vOs6W1fy7JlsGGJEk6V3NxZfDvqmp9VY227e3Aw1W1Fni4bQNcD6xty1bgXuiEB3AHcA2wAbjjTIBIkubH0vNwzs3AB9v6LuB/Ap9t9QeqqoBHkyxLsqK1PVBVpwCSHADGgK+fh77pArFm+3eH3YW+vHDXR4bdBWlODHplUMDfJzmcZGurXVlVJ9r6z4Er2/pK4MWuY4+12lR1SdI8GfTK4Per6niSfw0cSPKT7p1VVUlqwO/4Ry1wtgK8613vmqvTStJFb6Arg6o63j5PAt+hc8//pXb7h/Z5sjU/DqzuOnxVq01V7/V9O6pqtKpGR0ZGBum6JKnLrMMgyduS/OaZdWAT8BSwFzgzI2gL8GBb3wvc0mYVbQRebbeT9gObkixvD443tZokaZ4McpvoSuA7Sc6c52+r6u+SHAL2JLkV+BnwsdZ+H3ADMAH8CvgEQFWdSvIF4FBr9/kzD5MlSfNj1mFQVc8Dv9uj/gvgQz3qBWyb4lw7gZ2z7YskaTD+AlmSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRxft5aKuksvoVVC51XBpIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJOHrKBYFX3UgaVBeGUiSDANJkmEgSWIBPTNIMgb8V2AJ8DdVddeQuyRpGj6rWlwWRBgkWQJ8BfgwcAw4lGRvVT093J5Julhc7OG2UG4TbQAmqur5qvo1sBvYPOQ+SdJFI1U17D6Q5KPAWFX9h7b9ceCaqrrtrHZbga1t87eBZ+e1o9O7AviHYXdiDi228cDiG9NiGw8svjEtxPH8m6oaObu4IG4T9auqdgA7ht2PXpKMV9XosPsxVxbbeGDxjWmxjQcW35gupPEslNtEx4HVXdurWk2SNA8WShgcAtYmuSrJpcBNwN4h90mSLhoL4jZRVZ1Ochuwn87U0p1VdXTI3TpXC/L21QAW23hg8Y1psY0HFt+YLpjxLIgHyJKk4Voot4kkSUNkGEiSDINBJRlL8mySiSTbh92fQSXZmeRkkqeG3Ze5kGR1koNJnk5yNMmnh92nQSV5a5LHk/y4jelzw+7TXEiyJMmPkjw07L7MhSQvJHkyyZEk48Puz0x8ZjCA9hqN/03XazSAmy/k12gk+QPgdeCBqnrvsPszqCQrgBVV9cMkvwkcBm68wP83CvC2qno9ySXAI8Cnq+rRIXdtIEn+EzAKvKOq/nDY/RlUkheA0apaaD8668krg8EsutdoVNUPgFPD7sdcqaoTVfXDtv5L4Blg5XB7NZjqeL1tXtKWC/qvuiSrgI8AfzPsvlysDIPBrARe7No+xgX+D81ilmQN8D7gseH2ZHDtlsoR4CRwoKou9DH9F+DPgf837I7MoQL+Psnh9iqdBc0w0EUhyduBbwGfqarXht2fQVXVm1W1ns6v9TckuWBv6SX5Q+BkVR0edl/m2O9X1dXA9cC2dgt2wTIMBuNrNC4A7b76t4CvVdW3h92fuVRVrwAHgbFh92UAHwD+qN1j3w1cm+R/DLdLg6uq4+3zJPAdOreVFyzDYDC+RmOBaw9b7wOeqaovD7s/cyHJSJJlbf0yOhMYfjLcXs1eVd1eVauqag2d/w99v6r+/ZC7NZAkb2sTFkjyNmATsKBn6BkGA6iq08CZ12g8A+y5AF+j8c8k+Trwv4DfTnIsya3D7tOAPgB8nM5fm0facsOwOzWgFcDBJE/Q+YPkQFUtiumYi8iVwCNJfgw8Dny3qv5uyH2allNLJUleGUiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJKA/w/YG+7a4j0mJAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jaGOmPe9N0D"
      },
      "source": [
        "## Test dataset class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "kAXSxdRI8a9i",
        "outputId": "1f6c98e8-8e99-42ed-f89a-742555e35cf3"
      },
      "source": [
        "class_distribution = distribution_dataset([e[2].item() for e in list(test_dataset)])\n",
        "print(class_distribution)\n",
        "y = list(class_distribution.keys())\n",
        "x = list(class_distribution.values())\n",
        "plt.bar(y, x, color=\"tab:orange\")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 8570, 5: 74, 2: 1263, 3: 782, 1: 275, 4: 119}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 6 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PabB9eGV--Xz"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJcywstmfibI",
        "outputId": "1c23e641-9c7a-4ecd-b873-7f032ad6fc7c"
      },
      "source": [
        "model, stats = train_classifier(\n",
        "    model = model,\n",
        "    dataset = train_dataset,\n",
        "    validation_ratio = 0.9,\n",
        "    batch_size = 32,\n",
        "    freeze_embeddings_layer = False,\n",
        "    freeze_encoder_layers = 0,\n",
        "    epochs = 1\n",
        ")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of  1,247.    Elapsed: 0:00:37.\n",
            "  Batch    80  of  1,247.    Elapsed: 0:01:15.\n",
            "  Batch   120  of  1,247.    Elapsed: 0:01:52.\n",
            "  Batch   160  of  1,247.    Elapsed: 0:02:30.\n",
            "  Batch   200  of  1,247.    Elapsed: 0:03:07.\n",
            "  Batch   240  of  1,247.    Elapsed: 0:03:44.\n",
            "  Batch   280  of  1,247.    Elapsed: 0:04:22.\n",
            "  Batch   320  of  1,247.    Elapsed: 0:04:59.\n",
            "  Batch   360  of  1,247.    Elapsed: 0:05:36.\n",
            "  Batch   400  of  1,247.    Elapsed: 0:06:14.\n",
            "  Batch   440  of  1,247.    Elapsed: 0:06:51.\n",
            "  Batch   480  of  1,247.    Elapsed: 0:07:28.\n",
            "  Batch   520  of  1,247.    Elapsed: 0:08:05.\n",
            "  Batch   560  of  1,247.    Elapsed: 0:08:43.\n",
            "  Batch   600  of  1,247.    Elapsed: 0:09:20.\n",
            "  Batch   640  of  1,247.    Elapsed: 0:09:57.\n",
            "  Batch   680  of  1,247.    Elapsed: 0:10:35.\n",
            "  Batch   720  of  1,247.    Elapsed: 0:11:12.\n",
            "  Batch   760  of  1,247.    Elapsed: 0:11:49.\n",
            "  Batch   800  of  1,247.    Elapsed: 0:12:27.\n",
            "  Batch   840  of  1,247.    Elapsed: 0:13:04.\n",
            "  Batch   880  of  1,247.    Elapsed: 0:13:41.\n",
            "  Batch   920  of  1,247.    Elapsed: 0:14:19.\n",
            "  Batch   960  of  1,247.    Elapsed: 0:14:56.\n",
            "  Batch 1,000  of  1,247.    Elapsed: 0:15:33.\n",
            "  Batch 1,040  of  1,247.    Elapsed: 0:16:11.\n",
            "  Batch 1,080  of  1,247.    Elapsed: 0:16:48.\n",
            "  Batch 1,120  of  1,247.    Elapsed: 0:17:25.\n",
            "  Batch 1,160  of  1,247.    Elapsed: 0:18:03.\n",
            "  Batch 1,200  of  1,247.    Elapsed: 0:18:40.\n",
            "  Batch 1,240  of  1,247.    Elapsed: 0:19:18.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Training epcoh took: 0:19:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:49\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:20:13 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqDT_mFv_Z6D"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzchdYSYflEk",
        "outputId": "1123f02c-7ef5-47ff-cd92-8570ca32bba8"
      },
      "source": [
        "predictions, true_labels = test_classifier(\n",
        "    model = model,\n",
        "    dataset = test_dataset,\n",
        "    batch_size = 32\n",
        ")"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "\n",
            "Running Prediction...\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa2G8tqt-0m5"
      },
      "source": [
        "## Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnZA-iFjKVcz",
        "outputId": "34dc9df4-88ac-489f-9da0-dfa0063af9a6"
      },
      "source": [
        "print_performance_metrics(predictions, true_labels)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion Matrix\n",
            "Rows - Actual\n",
            "Columns - Predicted\n",
            "\n",
            "    |      0     1     2     3     4     5 | \n",
            "---------------------------------------------------\n",
            "  0 |  75.66  0.26  0.72  0.62  0.06  0.00 |  77.33\n",
            "  1 |   0.32  2.00  0.05  0.09  0.01  0.02 |   2.48\n",
            "  2 |   0.21  0.05 11.04  0.05  0.05  0.00 |  11.40\n",
            "  3 |   0.20  0.24  0.02  6.57  0.00  0.03 |   7.06\n",
            "  4 |   0.06  0.01  0.04  0.01  0.93  0.03 |   1.07\n",
            "  5 |   0.17  0.05  0.01  0.23  0.02  0.20 |   0.67\n",
            "---------------------------------------------------\n",
            "    |  76.61  2.61 11.87  7.57  1.06  0.27 | \n",
            "\n",
            "Majority Class                     :  0.7733\n",
            "Accuracy                           :  0.9640\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sxFc2YnKxNu"
      },
      "source": [
        "**Saving model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2-tX5WrK69X"
      },
      "source": [
        "save_model(\"drive/MyDrive/models/multiclass.pt\", model)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GNypsLqF2yZ"
      },
      "source": [
        "# Binary Slo classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUal_lBGHIhg"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmO7fvWwJO1i"
      },
      "source": [
        "binary_data = pd.read_csv('drive/MyDrive/Data/Slo/Binary/data.csv')\n",
        "x,y = run_dataset_preparation(binary_data, \"slo\", remove_stopwords=True, do_lemmatization=True)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvqimCWXJpVx",
        "outputId": "67031f7f-33f1-475c-f90e-eca1fc0a6b5a"
      },
      "source": [
        "model = setup_classifier(\n",
        "    model_name = \"drive/MyDrive/classifiers/bert/CroSloEngual\",\n",
        "    num_labels = 2\n",
        ")\n",
        "\n",
        "model.load_state_dict(load_model(\"drive/MyDrive/models/binary.pt\"))\n",
        "\n",
        "dataset = setup_data(\n",
        "    model_name = \"drive/MyDrive/classifiers/bert/CroSloEngual\",\n",
        "    x = x,\n",
        "    y = y,\n",
        "    do_lower_case = False,\n",
        "    max_length = 180\n",
        ")"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at drive/MyDrive/classifiers/bert/CroSloEngual were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/classifiers/bert/CroSloEngual and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Pps0-nKJebL"
      },
      "source": [
        "## Dataset class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "0ONk_sMDJh8I",
        "outputId": "907d08b4-f7e8-4ffe-9321-862b32e673cb"
      },
      "source": [
        "class_distribution = distribution_dataset([e[2].item() for e in list(dataset)])\n",
        "print(class_distribution)\n",
        "y = list(class_distribution.keys())\n",
        "x = list(class_distribution.values())\n",
        "plt.bar(y, x, color=\"tab:blue\")"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 1068, 1: 426}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 2 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU5-9XAJKd0e"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A1FtiFjKhMW",
        "outputId": "e97956bf-4a29-4133-f22f-bc4c8c6967b0"
      },
      "source": [
        "predictions, true_labels = test_classifier(\n",
        "    model = model,\n",
        "    dataset = dataset,\n",
        "    batch_size = 32\n",
        ")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "\n",
            "Running Prediction...\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA6ec1eWKoP_"
      },
      "source": [
        "## Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka6vtupgKtDX",
        "outputId": "7ec0bc12-612e-460a-fdd6-bb9c209ea82e"
      },
      "source": [
        "print_performance_metrics(predictions, true_labels)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion Matrix\n",
            "Rows - Actual\n",
            "Columns - Predicted\n",
            "\n",
            "    |      0     1 | \n",
            "---------------------------\n",
            "  0 |  70.35  1.14 |  71.49\n",
            "  1 |  27.71  0.80 |  28.51\n",
            "---------------------------\n",
            "    |  98.06  1.94 | \n",
            "\n",
            "Majority Class                     :  0.7149\n",
            "Accuracy                           :  0.7115\n",
            "\n",
            "Sensitivity, Recall                :  0.9841\n",
            "Specificity                        :  0.0282\n",
            "Positive Predictive, Precision     :  0.7174\n",
            "Negative Predictive                :  0.4138\n",
            "F1 Score                           :  0.8298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OlFLGTlF-16"
      },
      "source": [
        "# Multiclass Slo classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvOLyHovHLed"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V56lHYT3LMw2"
      },
      "source": [
        "multiclass_data = pd.read_csv('drive/MyDrive/Data/Slo/Multiclass/data.csv')\n",
        "x,y = run_dataset_preparation(multiclass_data, \"slo\", remove_stopwords=True, do_lemmatization=True)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vt4carMLfbQ",
        "outputId": "70af041e-2af2-4726-efc7-31cef2c6dd3a"
      },
      "source": [
        "model = setup_classifier(\n",
        "    model_name = \"drive/MyDrive/classifiers/bert/CroSloEngual\",\n",
        "    num_labels = 6\n",
        ")\n",
        "\n",
        "model.load_state_dict(load_model(\"drive/MyDrive/models/multiclass.pt\"))\n",
        "\n",
        "dataset = setup_data(\n",
        "    model_name = \"drive/MyDrive/classifiers/bert/CroSloEngual\",\n",
        "    x = x,\n",
        "    y = y,\n",
        "    do_lower_case = False,\n",
        "    max_length = 180\n",
        ")"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at drive/MyDrive/classifiers/bert/CroSloEngual were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/classifiers/bert/CroSloEngual and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW09iJBbLC23"
      },
      "source": [
        "## Dataset class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "CocSmJk0LtCi",
        "outputId": "685bd225-d1f9-449f-bdc4-f3c6df981aab"
      },
      "source": [
        "class_distribution = distribution_dataset([e[2].item() for e in list(dataset)])\n",
        "print(class_distribution)\n",
        "y = list(class_distribution.keys())\n",
        "x = list(class_distribution.values())\n",
        "plt.bar(y, x, color=\"tab:blue\")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 1068, 5: 357, 4: 8, 1: 26, 2: 20, 3: 23}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 6 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8_g6yNTLE-U"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KRbf7cFR19Q",
        "outputId": "87b6df92-3cd8-44a5-dae1-3696e06bbb37"
      },
      "source": [
        "predictions, true_labels = test_classifier(\n",
        "    model = model,\n",
        "    dataset = dataset,\n",
        "    batch_size = 32\n",
        ")"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "\n",
            "Running Prediction...\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XiuvOciLHoR"
      },
      "source": [
        "## Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5eT-0fFR6o5",
        "outputId": "815ea6fc-7353-479b-b0f1-fa17914c8e50"
      },
      "source": [
        "print_performance_metrics(predictions, true_labels)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion Matrix\n",
            "Rows - Actual\n",
            "Columns - Predicted\n",
            "\n",
            "    |      0     1     2     3     4     5 | \n",
            "---------------------------------------------------\n",
            "  0 |  70.84  0.13  0.07  0.07  0.00  0.00 |  71.11\n",
            "  1 |   1.73  0.00  0.00  0.00  0.00  0.00 |   1.73\n",
            "  2 |   1.33  0.00  0.00  0.00  0.00  0.00 |   1.33\n",
            "  3 |   1.53  0.00  0.00  0.00  0.00  0.00 |   1.53\n",
            "  4 |   0.53  0.00  0.00  0.00  0.00  0.00 |   0.53\n",
            "  5 |  23.77  0.00  0.00  0.00  0.00  0.00 |  23.77\n",
            "---------------------------------------------------\n",
            "    |  99.73  0.13  0.07  0.07  0.00  0.00 | \n",
            "\n",
            "Majority Class                     :  0.7111\n",
            "Accuracy                           :  0.7084\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}